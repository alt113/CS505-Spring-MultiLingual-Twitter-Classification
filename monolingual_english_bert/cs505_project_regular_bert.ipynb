{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs505 project regular bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FG99WpWvXoR",
        "outputId": "84dc63e0-2be4-4b9e-e2b7-7a21a739b863"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WelbEwVkE5Zx",
        "outputId": "a1baf5e9-941b-4d96-da17-abf7c2fd4a4e"
      },
      "source": [
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "from transformers import BertTokenizer, XLMRobertaTokenizer\n",
        "import numpy as np\n",
        "\n",
        "df1 = pd.read_csv(\"/english_train_tweets.csv\")#,sep='delimiter',encoding='utf-8')\n",
        "df2 = pd.read_csv(\"/english_test_tweets.csv\")\n",
        "frames=[df1,df2]\n",
        "df=pd.concat(frames)\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.preprocessed.values\n",
        "df.sentiment[df.sentiment == 'positive'] = 1\n",
        "df.sentiment[df.sentiment == 'negative'] = 0\n",
        "df.sentiment[df.sentiment == 'neutral'] = 2\n",
        "labels = df.sentiment.values\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5f1pHEIGDFh",
        "outputId": "9e1c7cdb-d350-4008-f046-368fdedcc8a1"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  1274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0MtVbOsGGZP",
        "outputId": "eb6bcc24-d383-4383-da81-e60c1c0d46ed"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels=[int(x) for x in labels]\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcc25h6jwTeG",
        "outputId": "a804b2ed-e83f-4c46-cd7e-64c5b0f48a06"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40,060 training samples\n",
            "4,452 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ZKYaXpz3F9",
        "outputId": "e7c54c6d-8ebc-4509-d29d-82ec638ac43f"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import XLMRobertaConfig, XLMRobertaForSequenceClassification\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n",
        "\n",
        "# For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the BERT paper):\n",
        "# Batch size: 16, 32\n",
        "# Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "# Number of epochs: 2, 3, 4\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4srI0Va20tEv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMT_T8YU0v9U",
        "outputId": "325aa4b4-edc8-4eee-f217-9c324103a23b"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch   100  of  1,252.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,252.    Elapsed: 0:01:08.\n",
            "  Batch   300  of  1,252.    Elapsed: 0:01:43.\n",
            "  Batch   400  of  1,252.    Elapsed: 0:02:19.\n",
            "  Batch   500  of  1,252.    Elapsed: 0:02:56.\n",
            "  Batch   600  of  1,252.    Elapsed: 0:03:33.\n",
            "  Batch   700  of  1,252.    Elapsed: 0:04:09.\n",
            "  Batch   800  of  1,252.    Elapsed: 0:04:46.\n",
            "  Batch   900  of  1,252.    Elapsed: 0:05:23.\n",
            "  Batch 1,000  of  1,252.    Elapsed: 0:06:00.\n",
            "  Batch 1,100  of  1,252.    Elapsed: 0:06:37.\n",
            "  Batch 1,200  of  1,252.    Elapsed: 0:07:13.\n",
            "\n",
            "  Average training loss: 0.75\n",
            "  Training epcoh took: 0:07:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.68\n",
            "  Validation took: 0:00:18\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:07:50 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "4gNae3tC1L2Y",
        "outputId": "942fbf32-161c-47bc-afc2-1130f41d9659"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMY8fbZfQxaX",
        "outputId": "55af4099-61a0-4fe1-e1a0-7964adbb36ae"
      },
      "source": [
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "from transformers import BertTokenizer\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import torch\n",
        "\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df=pd.read_csv(\"/arabic_test.csv\",encoding='utf-8')\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df=df.dropna(subset=['preprocessed'])\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.preprocessed.values\n",
        "df.sentiment[df.sentiment == 'positive'] = 1\n",
        "df.sentiment[df.sentiment == 'negative'] = 0\n",
        "df.sentiment[df.sentiment == 'neutral'] = 2\n",
        "labels = df.sentiment.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "count=0\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    #if count > 70:\n",
        "    #  print(sent)\n",
        "    #  print(count)\n",
        "    #count+=1\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels=[int(x) for x in labels]\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 3,355\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FAZBr99SpZF",
        "outputId": "9472b247-dff0-46f1-d5c7-faa5f48c57c1"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,338 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2rhTfnuSv58",
        "outputId": "d12715a7-1038-4bfa-857c-44bdf594657e"
      },
      "source": [
        "predictions=[item for sublist in predictions for item in sublist]\n",
        "predictions=[round(torch.softmax(torch.tensor(x),dim=0).numpy()[1]) for x in predictions]\n",
        "#print(predictions)\n",
        "#print(type(result))\n",
        "#print(true_labels)\n",
        "from sklearn.metrics import accuracy_score\n",
        "true_labels=[item for sublist in true_labels for item in sublist]\n",
        "#print(len(true_labels))\n",
        "accuracy=accuracy_score(true_labels,predictions)\n",
        "print(accuracy)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3406231276213301\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}